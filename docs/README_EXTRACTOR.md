# M√≥dulo de Extracci√≥n de Art√≠culos Completos

## üìã Descripci√≥n

M√≥dulo complementario del **RSS China News Filter** que descarga y extrae el texto completo de art√≠culos de noticias desde sus URLs, produciendo contenido limpio y normalizado para an√°lisis posterior.

---

## üéØ Caracter√≠sticas

- ‚úÖ **Extracci√≥n robusta** con trafilatura (m√©todo principal)
- ‚úÖ **Fallbacks inteligentes** con BeautifulSoup y Playwright
- ‚úÖ **Detecci√≥n de bloqueos** y manejo de captchas
- ‚úÖ **Limpieza de texto** autom√°tica (elimina ruido, men√∫s, scripts)
- ‚úÖ **Detecci√≥n de idioma** y extracci√≥n de metadatos
- ‚úÖ **Concurrencia configurable** para procesamiento eficiente
- ‚úÖ **Logging detallado** y reportes de ejecuci√≥n
- ‚úÖ **Salida en JSONL y CSV** compatible con Excel

---

## üì¶ Instalaci√≥n

### 1. Instalar dependencias

```bash
# Activar entorno virtual
cd f:/pautalla/china
.venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

### 2. Instalar Playwright (opcional)

**Solo si necesitas fallback con JavaScript**:

```bash
# Instalar navegador Chromium
playwright install chromium
```

---

## ‚öôÔ∏è Configuraci√≥n

Editar `config/extractor_config.yaml` seg√∫n necesidades:

```yaml
# Configuraci√≥n b√°sica
downloader:
  timeout: 15
  concurrency: 5
  delay_between_requests_same_domain: 1.0

extractor:
  min_text_length_ok: 200
  favor_precision: true

fallback:
  playwright_enabled: false  # Activar solo si es necesario
```

**Ver**: `docs/ESPECIFICACION_EXTRACTOR_ARTICULOS.md` para detalles completos.

---

## üöÄ Uso

### Ejecuci√≥n B√°sica

```bash
# Extraer art√≠culos desde output.jsonl
python src/main_extractor.py
```

### Opciones Avanzadas

```bash
# Especificar archivos de entrada/salida
python src/main_extractor.py \
    --input data/output.jsonl \
    --output data/articles_full.jsonl

# Ajustar concurrencia
python src/main_extractor.py --concurrency 10

# Activar fallback con Playwright
python src/main_extractor.py --enable-playwright

# Modo debug
python src/main_extractor.py --log-level DEBUG

# Procesar solo primeros N art√≠culos (testing)
python src/main_extractor.py --max-articles 10
```

### Ayuda

```bash
python src/main_extractor.py --help
```

---

## üìä Formato de Salida

### Archivo JSONL (`articles_full.jsonl`)

Cada l√≠nea es un objeto JSON con:

```json
{
  "nombre_del_medio": "El Pa√≠s",
  "enlace": "https://elpais.com/internacional/...",
  "titular": "China anuncia nuevas medidas econ√≥micas",
  "fecha": "2025-11-26T10:30:00+00:00",
  "descripcion": "El gobierno chino presenta...",
  "texto": "El gobierno de China anunci√≥ este martes...\n\nLas autoridades econ√≥micas...",
  "idioma": "es",
  "autor": "Juan P√©rez",
  "fecha_publicacion": "2025-11-26T10:00:00+00:00",
  "scrape_status": "ok",
  "error_message": "",
  "extraction_method": "trafilatura",
  "char_count": 3542,
  "word_count": 587,
  "download_time": 2.34,
  "extraction_time": 0.12
}
```

### Archivo CSV (`articles_full.csv`)

Formato CSV con UTF-8 BOM (compatible con Excel):

| nombre_del_medio | enlace | titular | texto | scrape_status | ... |
|-----------------|--------|---------|-------|---------------|-----|
| El Pa√≠s | https://... | ... | ... | ok | ... |

### Archivo de Fallos (`failed_extractions.jsonl`)

URLs que fallaron con raz√≥n del fallo:

```json
{
  "url": "https://ejemplo.com/articulo",
  "nombre_del_medio": "Ejemplo",
  "titular": "...",
  "scrape_status": "error_descarga",
  "error_message": "HTTP 404 Not Found",
  "timestamp": "2025-11-26T18:15:32"
}
```

### Reporte de Ejecuci√≥n (`extraction_report.json`)

Resumen completo de la ejecuci√≥n:

```json
{
  "execution_summary": {
    "start_time": "2025-11-26T18:00:00",
    "end_time": "2025-11-26T18:12:34",
    "duration_seconds": 754,
    "total_articles": 100
  },
  "results": {
    "successful": 87,
    "failed_download": 5,
    "failed_extraction": 3,
    "no_content": 4,
    "blocked": 1
  },
  "extraction_methods": {
    "trafilatura": 82,
    "bs4_fallback": 5,
    "playwright": 0
  }
}
```

---

## üîÑ Flujo de Trabajo T√≠pico

```
1. Ejecutar filtrado RSS
   ‚Üí python src/main.py --async
   ‚Üí Genera: data/output.jsonl

2. Extraer texto completo
   ‚Üí python src/main_extractor.py
   ‚Üí Genera: data/articles_full.jsonl

3. Revisar resultados
   ‚Üí Ver: data/extraction_report.json
   ‚Üí Revisar: data/failed_extractions.jsonl

4. Analizar art√≠culos
   ‚Üí Usar: data/articles_full.jsonl
```

---

## üìà Rendimiento

### Tiempos Estimados

| Art√≠culos | Concurrency | Tiempo Estimado |
|-----------|-------------|-----------------|
| 10 | 1 | ~1 min |
| 50 | 5 | ~2-3 min |
| 100 | 5 | ~5-8 min |
| 500 | 10 | ~15-20 min |

### Recursos

- **RAM**: ~100-200 MB (sin Playwright)
- **RAM**: ~500 MB - 1 GB (con Playwright)
- **CPU**: 1-2 cores al 50-80%
- **Red**: ~5-10 MB descargados por 100 art√≠culos

---

## üõ†Ô∏è M√©todos de Extracci√≥n

### 1. Trafilatura (Principal)

**Cu√°ndo**: Siempre como primer intento

**Ventajas**:
- R√°pido (~100ms)
- Preciso para mayor√≠a de sitios
- Detecta idioma autom√°ticamente

**Limitaciones**:
- No funciona con JavaScript
- Puede fallar con HTML no est√°ndar

---

### 2. BeautifulSoup (Fallback 1)

**Cu√°ndo**: Si trafilatura falla o texto < 100 caracteres

**Ventajas**:
- R√°pido (~50-100ms adicionales)
- Personalizable por dominio
- No requiere recursos extra

**Selectores configurados**:
- El Pa√≠s
- El Mundo
- ABC
- La Vanguardia
- La Raz√≥n

---

### 3. Playwright (Fallback 2)

**Cu√°ndo**: Solo si niveles 1 y 2 fallan + dominio en whitelist

**Ventajas**:
- Ejecuta JavaScript
- Renderiza contenido din√°mico

**Limitaciones**:
- Lento (~5-10s)
- Alto consumo de recursos
- Requiere instalaci√≥n adicional

**Configuraci√≥n**:
```yaml
fallback:
  playwright_enabled: false  # Desactivado por defecto
  playwright_whitelist_domains: []  # A√±adir solo si es necesario
```

---

## üö® Estados de Extracci√≥n

| scrape_status | Significado | Acci√≥n |
|---------------|-------------|--------|
| `ok` | Extracci√≥n exitosa | ‚úÖ Usar texto |
| `no_contenido_detectado` | Texto muy corto o vac√≠o | ‚ö†Ô∏è Revisar URL |
| `error_descarga` | Error HTTP o timeout | ‚ùå Verificar URL |
| `error_parseo` | Error al parsear HTML | ‚ö†Ô∏è Revisar estructura |
| `blocked_fallback_required` | Bloqueo detectado | üîí Requiere Playwright |

---

## üìù Ejemplos de Uso

### Ejemplo 1: Extracci√≥n B√°sica

```bash
# Extraer todos los art√≠culos de output.jsonl
python src/main_extractor.py

# Ver resultados
cat data/extraction_report.json
```

### Ejemplo 2: Testing con Pocos Art√≠culos

```bash
# Procesar solo 5 art√≠culos para probar
python src/main_extractor.py --max-articles 5 --log-level DEBUG
```

### Ejemplo 3: Activar Playwright

```bash
# 1. Editar config/extractor_config.yaml
#    playwright_enabled: true
#    playwright_whitelist_domains: ["ejemplo.com"]

# 2. Ejecutar
python src/main_extractor.py --enable-playwright
```

### Ejemplo 4: An√°lisis de Resultados

```bash
# Contar art√≠culos exitosos
grep '"scrape_status": "ok"' data/articles_full.jsonl | wc -l

# Ver art√≠culos fallidos
cat data/failed_extractions.jsonl

# Estad√≠sticas de longitud de texto
jq -r 'select(.scrape_status=="ok") | .char_count' data/articles_full.jsonl | \
  awk '{sum+=$1; count++} END {print "Promedio:", sum/count, "caracteres"}'
```

---

## üîç Troubleshooting

### Problema: Alta tasa de fallos

**Soluci√≥n**:
1. Revisar `failed_extractions.jsonl` para identificar patrones
2. Verificar conectividad de red
3. Aumentar timeout en config
4. A√±adir selectores BS4 espec√≠ficos para dominios problem√°ticos

### Problema: Texto extra√≠do contiene ruido

**Soluci√≥n**:
1. Revisar patrones de limpieza en config
2. A√±adir patrones espec√≠ficos en `cleaner.remove_patterns`
3. Ajustar selectores BS4 para ser m√°s espec√≠ficos

### Problema: Bloqueos frecuentes

**Soluci√≥n**:
1. Aumentar `delay_between_requests_same_domain`
2. Reducir `concurrency`
3. Verificar si dominio requiere Playwright
4. Considerar usar proxy (implementaci√≥n futura)

### Problema: Playwright muy lento

**Soluci√≥n**:
1. Reducir `max_playwright_calls_per_run`
2. Revisar whitelist (solo dominios esenciales)
3. Buscar selectores BS4 alternativos
4. Considerar desactivar Playwright

---

## üìö Documentaci√≥n Adicional

- **Especificaci√≥n completa**: `docs/ESPECIFICACION_EXTRACTOR_ARTICULOS.md`
- **Estrategia de fallback**: `docs/ESTRATEGIA_FALLBACK.md`
- **Configuraci√≥n**: `config/extractor_config.yaml`

---

## üîó Integraci√≥n con GUI

El m√≥dulo se puede ejecutar desde la GUI principal:

1. Abrir GUI: `python src/gui.py`
2. Ejecutar filtrado RSS
3. Clic en bot√≥n **"üìù Extraer Texto Completo"**
4. Ver resultados en tab "Art√≠culos Completos"

---

## üìÖ Mantenimiento

### Diario
- Ejecutar extracci√≥n despu√©s de filtrado RSS
- Revisar `extraction_report.json`
- Verificar `failed_extractions.jsonl`

### Semanal
- Revisar logs para errores recurrentes
- Validar calidad de texto extra√≠do (muestra aleatoria)

### Mensual
- Actualizar selectores BS4 si sitios cambiaron
- Revisar y ajustar configuraci√≥n
- Limpiar logs antiguos

---

## ü§ù Contribuir

Para a√±adir soporte para nuevos medios:

1. Identificar selectores CSS del contenido principal
2. A√±adir a `extractor_config.yaml`:
   ```yaml
   domain_selectors:
     nuevo-medio.com:
       - "selector-principal"
       - "selector-alternativo"
   ```
3. Probar con art√≠culos reales
4. Documentar en este README

---

## üìÑ Licencia

Proyecto educativo/interno - RSS China News Filter

---

## üÜò Soporte

Para problemas o preguntas:
1. Revisar documentaci√≥n en `docs/`
2. Verificar logs en `logs/article_extractor.log`
3. Ejecutar con `--log-level DEBUG` para m√°s detalles

---

**√öltima actualizaci√≥n**: 2025-11-26
